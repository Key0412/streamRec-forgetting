{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação em holdouts - Amazon Books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interactions in the 'Amazon Books' dataset are well distributed.\n",
    "Several users are present during the whole considered period (2014):\n",
    "<!-- * 37067 users of 190248 (19.484%) occurr in 80.0% or more months. -->\n",
    "* 500 users of 500 (100.0%) occurr in 80.0% or more months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('') + '/..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import ImplicitData, getBucketsHoldouts\n",
    "from plot_utils import lineplot_recallxholdout, recall_heatmap\n",
    "from dataset_evaluation_utils import *\n",
    "from recommenders_implicit import ISGD, RAISGD, RSISGD  # ISGD framework, BISGD,\n",
    "from eval_implicit import EvaluateHoldouts, EvaluateAndStore # EvaluateAndStore para guardar estados do modelo e holdouts, a avaliação prequencial de ratings implicitos é opcional, , EvalHoldout\n",
    "\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## BWT FWT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACC, BWT, e FWT - Lopez-Paz e Ranzato GEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_recall(results_matrix): # Lopez-Paz e Ranzato GEM 2017\n",
    "    return np.mean( np.diag(results_matrix) )\n",
    "\n",
    "def compute_BWT(results_matrix): # Lopez-Paz e Ranzato GEM 2017\n",
    "    BWT = []\n",
    "    n_checkpoints = results_matrix.shape[0]\n",
    "    for T in range(1, n_checkpoints): # 1 means holdout 2, 2 means 3, so on\n",
    "        Rti = results_matrix.iloc[T, 0:T] # get models performances' on previous holdouts\n",
    "        Rii = np.diag(results_matrix)[0:T] # get models performances' on their closest holdouts (diagonal)\n",
    "        E = sum( Rti - Rii ) # future models performances' - performances' of models closest to holdouts (diagonal)\n",
    "        BWT.append( E/T ) # store average BWT for model\n",
    "    return BWT, np.mean( BWT ) # return BWT and average BWT for all models\n",
    "\n",
    "def compute_FWT(results_matrix): # Díaz-Rodriguez et al. 2018\n",
    "    upper_tri = results_matrix.to_numpy()[np.triu_indices(results_matrix.shape[0], k=1)]\n",
    "    return np.mean(upper_tri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "___\n",
    "# Amazon Books\n",
    "Small subset, ratings only.  \n",
    "https://nijianmo.github.io/amazon/index.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa dataset 'books playlists'\n",
    "data = pd.read_csv('output/amazonbooks_dump/2nd_sampled_amazon_books.csv')\n",
    "dataset_name = 'Amazon_Books'\n",
    "user_col = 'user_id'\n",
    "item_col = 'item_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(564099, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0141353678</td>\n",
       "      <td>A2YYLQVZSEPYH7</td>\n",
       "      <td>1388534400</td>\n",
       "      <td>2014-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0812469496</td>\n",
       "      <td>A139ERFHMIYLXL</td>\n",
       "      <td>1388534400</td>\n",
       "      <td>2014-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0297867288</td>\n",
       "      <td>A2LF0FQQG9ANHJ</td>\n",
       "      <td>1388534400</td>\n",
       "      <td>2014-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0297867288</td>\n",
       "      <td>A2T098MZGADPLT</td>\n",
       "      <td>1388534400</td>\n",
       "      <td>2014-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0297867288</td>\n",
       "      <td>A1NTTZPH8YU0FN</td>\n",
       "      <td>1388534400</td>\n",
       "      <td>2014-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id         item_id   timestamp        date\n",
       "0  0141353678  A2YYLQVZSEPYH7  1388534400  2014-01-01\n",
       "1  0812469496  A139ERFHMIYLXL  1388534400  2014-01-01\n",
       "2  0297867288  A2LF0FQQG9ANHJ  1388534400  2014-01-01\n",
       "3  0297867288  A2T098MZGADPLT  1388534400  2014-01-01\n",
       "4  0297867288  A1NTTZPH8YU0FN  1388534400  2014-01-01"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 564099 entries, 0 to 564098\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   user_id    564099 non-null  object\n",
      " 1   item_id    564099 non-null  object\n",
      " 2   timestamp  564099 non-null  int64 \n",
      " 3   date       564099 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 17.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/.virtualenvs/streamrec_venv/lib/python3.8/site-packages/pandas/core/series.py:4213\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4211\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4212\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 4213\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], Series):\n\u001b[1;32m   4216\u001b[0m     \u001b[38;5;66;03m# GH 25959 use pd.array instead of tolist\u001b[39;00m\n\u001b[1;32m   4217\u001b[0m     \u001b[38;5;66;03m# so extension arrays can be used\u001b[39;00m\n\u001b[1;32m   4218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_expanddim(pd\u001b[38;5;241m.\u001b[39marray(mapped), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32mpandas/_libs/lib.pyx:2403\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<timed exec>:2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3.8/_strptime.py:568\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[0;34m(cls, data_string, format)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_strptime_datetime\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data_string, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%a\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mb \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;124;03m    format string.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 568\u001b[0m     tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m     tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m    570\u001b[0m     args \u001b[38;5;241m=\u001b[39m tt[:\u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m+\u001b[39m (fraction,)\n",
      "File \u001b[0;32m/usr/lib/python3.8/_strptime.py:555\u001b[0m, in \u001b[0;36m_strptime\u001b[0;34m(data_string, format)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m leap_year_fix:\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;66;03m# the caller didn't supply a year but asked for Feb 29th. We couldn't\u001b[39;00m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;66;03m# use the default of 1900 for computations. We set it back to ensure\u001b[39;00m\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;66;03m# that February 29th is smaller than March 1st.\u001b[39;00m\n\u001b[1;32m    553\u001b[0m     year \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1900\u001b[39m\n\u001b[0;32m--> 555\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (year, month, day,\n\u001b[1;32m    556\u001b[0m         hour, minute, second,\n\u001b[1;32m    557\u001b[0m         weekday, julian, tz, tzname, gmtoff), fraction, gmtoff_fraction\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# 5s\n",
    "data['date'] = data['date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "data.sort_values(by='timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0141353678</td>\n",
       "      <td>A2YYLQVZSEPYH7</td>\n",
       "      <td>1388534400</td>\n",
       "      <td>2014-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0812469496</td>\n",
       "      <td>A139ERFHMIYLXL</td>\n",
       "      <td>1388534400</td>\n",
       "      <td>2014-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0297867288</td>\n",
       "      <td>A2LF0FQQG9ANHJ</td>\n",
       "      <td>1388534400</td>\n",
       "      <td>2014-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0297867288</td>\n",
       "      <td>A2T098MZGADPLT</td>\n",
       "      <td>1388534400</td>\n",
       "      <td>2014-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0297867288</td>\n",
       "      <td>A1NTTZPH8YU0FN</td>\n",
       "      <td>1388534400</td>\n",
       "      <td>2014-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id         item_id   timestamp        date\n",
       "0  0141353678  A2YYLQVZSEPYH7  1388534400  2014-01-01\n",
       "1  0812469496  A139ERFHMIYLXL  1388534400  2014-01-01\n",
       "2  0297867288  A2LF0FQQG9ANHJ  1388534400  2014-01-01\n",
       "3  0297867288  A2T098MZGADPLT  1388534400  2014-01-01\n",
       "4  0297867288  A1NTTZPH8YU0FN  1388534400  2014-01-01"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:6\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/.virtualenvs/streamrec_venv/lib/python3.8/site-packages/pandas/core/generic.py:5137\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5130\u001b[0m \u001b[38;5;66;03m# Note: obj.x will always call obj.__getattribute__('x') prior to\u001b[39;00m\n\u001b[1;32m   5131\u001b[0m \u001b[38;5;66;03m# calling obj.__getattr__('x').\u001b[39;00m\n\u001b[1;32m   5132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5133\u001b[0m     name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5134\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5135\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5136\u001b[0m ):\n\u001b[0;32m-> 5137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name):\n",
      "File \u001b[0;32m~/.virtualenvs/streamrec_venv/lib/python3.8/site-packages/pandas/core/accessor.py:187\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[0;32m--> 187\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[0;32m~/.virtualenvs/streamrec_venv/lib/python3.8/site-packages/pandas/core/indexes/accessors.py:480\u001b[0m, in \u001b[0;36mCombinedDatetimelikeProperties.__new__\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_period_dtype(data\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PeriodProperties(data, orig)\n\u001b[0;32m--> 480\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .dt accessor with datetimelike values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 198ms\n",
    "interactions_per_month = data.groupby(by=['date']).count().iloc[:, 0]\n",
    "interactions_per_month.name = 'count'\n",
    "interactions_per_month=interactions_per_month.reset_index()\n",
    "_ = interactions_per_month.copy()\n",
    "_['date'] = _['date'].dt.date\n",
    "_.groupby('date').sum().plot(kind='bar')\n",
    "plt.title('interactions per month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Get intervals and Frequent users (threshold = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_presence_df = pd.read_csv('output/amazonbooks_dump/2nd_sample_user_presence_df.csv')\n",
    "user_month_interactions = pd.read_csv('output/amazonbooks_dump/2nd_sample_user_month_interactions.csv')\n",
    "frequent_users_month = joblib.load('output/amazonbooks_dump/2nd_sample_frequent_users_month.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Experiments using months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(564099, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating buckets. . .\n",
      "Creating holdouts. . .\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 29.7 s\n",
    "buckets, holdouts = getBucketsHoldouts(\n",
    "    data=data,\n",
    "    user_col=user_col,\n",
    "    item_col=item_col,\n",
    "    frequent_users=frequent_users_month,\n",
    "    interval_type='M',\n",
    "    intervals=None, \n",
    "    cold_start_buckets=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debugging buckets and holdouts - **only works if they're not converted to implicit data in get_buckets_and_holdouts.getBucketsHoldouts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # join buckets and holdouts, to check if they have any equal interactions (they should not)\n",
    "# a = pd.concat( buckets ).set_index([user_col, item_col])\n",
    "# b = pd.concat( holdouts )[[user_col, item_col]].set_index([user_col, item_col])\n",
    "# a.join(b, how='inner').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # concatenate buckets and holdouts, to check if the result is equal to the original data (it should be equal)\n",
    "# _  = pd.concat( [pd.concat( buckets ), pd.concat( holdouts )], ignore_index=True).sort_values(by=['timestamp', 'user_id','item_id']).reset_index(drop=True)\n",
    "# _.equals(data.sort_values(by=['timestamp', 'user_id','item_id']).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket_sizes = [b.shape[0] for b in buckets]\n",
    "# holdout_sizes = [h.shape[0] for h in holdouts]\n",
    "# bucket_sizes, holdout_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(buckets, 'output/amazonbooks_dump/2nd_sample_buckets.joblib')\n",
    "joblib.dump(holdouts, 'output/amazonbooks_dump/2nd_sample_holdouts.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = joblib.load('output/amazonbooks_dump/2nd_sample_buckets.joblib')\n",
    "holdouts = joblib.load('output/amazonbooks_dump/2nd_sample_holdouts.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters (SAME AS LASTFM)\n",
    "num_factors = 160\n",
    "num_iter = 4\n",
    "learn_rate = 0.5\n",
    "regularization = 0.4\n",
    "num_nodes = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforma interações em objeto que contem mappings usuário-itens e item-usuários, contém também métodos de suporte. recebe listas\n",
    "# stream = ImplicitData(data[user_col], data[item_col])\n",
    "# O modelo deve ser iniciado com uma lista vazia\n",
    "empty_stream = ImplicitData([], [])\n",
    "# Se o stream for passado, ao excluir itens conhecidos o recall é sempre 0. Ao permitir a recomendação de itens já vistos, o recall não é 0.\n",
    "model = ISGD(empty_stream, num_factors, num_iter, learn_rate = learn_rate, u_regularization = regularization, i_regularization = regularization, random_seed = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 1d 14min 19s\n",
    "# criamos instancia de EvaluateHoldouts para treinar o modelo e criar checkpoints\n",
    "eval = EvaluateHoldouts(model=model, buckets=buckets, holdouts=holdouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 14h 22min 35s\n",
    "eval.EvaluateHoldouts(N_recommendations=20, exclude_known_items=True, default_user='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(eval, 'output/amazonbooks_dump/2nd_sample_amazon_books ISGD eval.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = eval.results_matrix\n",
    "df = pd.DataFrame(rm.T)\n",
    "df.to_csv('output/amazonbooks_dump/2nd_sample_amazon_books month_bucket ISGD results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_heatmap(df,\n",
    "    title='Recall@20 for ISGD models across Holdouts - Amazon Books',\n",
    "    filepath='images/heatmaps/amazonbooks_dump/2nd_sample_amazon_books month_bucket ISGD heatmap.png') #='images/heatmaps/palco_2010 month_bucket ISGD heatmap.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arecall = avg_recall(df)\n",
    "arecall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BWT, meanBWT = compute_BWT(df)\n",
    "BWT, meanBWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWT = compute_FWT(df)\n",
    "FWT\n",
    "# que itens que usuario utilizou no passado e deixou de consumir o sistema ainda pode recomendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BWT, meanBWT = compute_BWT(df)\n",
    "BWT, meanBWT"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93164e1ba08303257f1d4f69270dc17556e83319233af9462e0c249160adc063"
  },
  "kernelspec": {
   "display_name": "streamrec_venv",
   "language": "python",
   "name": "streamrec_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
